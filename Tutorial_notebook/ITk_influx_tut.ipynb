{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITk component population timeline plot tutorial\n",
    "\n",
    "In this tutorial we will create a plot of component population against time in the hope of generating a timeline of component stage migration. To do this we will be using some 3rd party software to: handle the time stamping of the data we will pull form the ITk database (influx), plotting the time stamped data (altair) and creating an interactive report of our plot to share (datapane). Before we begin lets us install some dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "requirements = ['pandas', 'itkdb', 'datapane', 'altair', 'influxdb_client']\n",
    "with open('requirements.txt', 'w') as my_list:\n",
    "    for element in requirements:\n",
    "        my_list.write('%s\\n' % element)\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get itkdb for PDB interaction\n",
    "import os\n",
    "import sys\n",
    "#pip install pandas\n",
    "import pandas as pd\n",
    "import copy\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "#pip install itkdb\n",
    "import itkdb\n",
    "import itkdb.exceptions as itkX\n",
    "# visualisation\n",
    "#pip install datapane\n",
    "#pip install altair\n",
    "import altair as alt\n",
    "import datapane as dp\n",
    "# influx \n",
    "#pip install influxdb_client\n",
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from influxdb_client.client.exceptions import InfluxDBError\n",
    "import warnings\n",
    "from influxdb_client.client.warnings import MissingPivotFunction\n",
    "\n",
    "warnings.simplefilter(\"ignore\", MissingPivotFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up ITk db\n",
    "user = itkdb.core.User(accessCode1=\"\", accessCode2=\"\")\n",
    "user.authenticate()\n",
    "myClient = itkdb.Client(user=user)\n",
    "print(user.name+\" your token expires in \"+str(myClient.user.expires_in)+\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### some filters and pull some data\n",
    "myProjCode=\"S\" #s for strips \n",
    "myCompCode=\"MODULE\"\n",
    "myInstCode=\"GL\"  #potential institue codes include:'IHEP', 'RAL', 'LIV', 'GL', 'BHM', 'SHF', 'CAM', 'OX','QMUL','CERN'\n",
    "compList = myClient.get('listComponents', json={'project':myProjCode, 'currentLocation':myInstCode})\n",
    "compList.page_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put data in pandas dataframe \n",
    "myData=myClient.get('listComponents', json={'project':\"S\",'currentLocation':myInstCode})\n",
    "df_data=pd.json_normalize(myData, sep = \"_\")\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group componentTypes\n",
    "df_data_grp=df_data.groupby(by=[\"componentType_code\"]).count().reset_index()\n",
    "df_data_grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influx install \n",
    "Before we proceed we will need to install influx and launch the daemon. please follow the instructions [on this page](https://portal.influxdata.com/downloads/) to install influxdb and then open the terminal and launch the daemon by typing \"influxd\" in the terminal (macOS). You need to acces the influx gui by typing [http://localhost:8086](http://localhost:8086/) in your browser of choice, continue with \"Get started\" and \"Setup initial user\".\n",
    "\n",
    "Input the Initial Organization Name in org_local and Initial Bucket Name in bucketName below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try a quick write to influx\n",
    "#\n",
    "org_local = \"\"\n",
    "bucketName=\"\"\n",
    "\n",
    "# Store the URL of your InfluxDB instance\n",
    "url_local=\"http://localhost:8086\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that: hit configure later, click the icon that is an arrow about a flat line, click API tokens, click on your token and copy and pase the token in to the varible below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_local = \"Your token goes here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set client to get access to influx\n",
    "clientV2_local = influxdb_client.InfluxDBClient(\n",
    "   url=url_local,\n",
    "   token=token_local,\n",
    "   org=org_local\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set bucket api\n",
    "buckets_api_local = clientV2_local.buckets_api()\n",
    "\n",
    "### list buckets (by name)\n",
    "try:\n",
    "    #print([x.name for x in buckets_api_remote.find_buckets().buckets])\n",
    "    database_list=[x.name for x in clientV2_local.buckets_api().find_buckets().buckets]\n",
    "    print(database_list)\n",
    "except:\n",
    "    print(\"cannot get buckets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### what bucket?\n",
    "### create bucket\n",
    "#buckets_api_local.create_bucket(bucket_name=bucketName, org=org_local)\n",
    "\n",
    "### find bucket\n",
    "buckets_api_local.find_bucket_by_name(bucketName)\n",
    "\n",
    "### delete bucket\n",
    "#buckets_api_local.delete_bucket(buckets_api_local.find_bucket_by_name(bucketName).id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set write api\n",
    "write_api_local = clientV2_local.write_api(write_options=SYNCHRONOUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the data\n",
    "for i in range(0,len(df_data_grp)):\n",
    "    def loc(x,y):\n",
    "        a=df_data_grp.loc[x,y]\n",
    "        return(a)\n",
    "    data=\"Strips_in_\"+str(myInstCode)+\",componentType_code=\"+str(loc(i,\"componentType_code\"))+\",id=\"+str(loc(i,\"id\"))+\" \"+\"code=\"+str(loc(i,\"code\"))\n",
    "    # write\n",
    "    write_api_local.write(bucketName, org_local, data)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup query API\n",
    "\n",
    "query_api_local = clientV2_local.query_api(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query the bucket\n",
    "\n",
    "query='''\n",
    "from(bucket: \"Bucketname\")\n",
    "  |> range(start: 0, stop: now())\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"Strips_in_XYZ\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"code\")\n",
    "  |> yield(name: \"mean\")\n",
    "'''\n",
    "a=query.replace(\"Bucketname\",str(bucketName))\n",
    "b=a.replace(\"XYZ\",str(myInstCode))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display query result\n",
    "\n",
    "query_result = query_api_local.query_data_frame(org=org_local, query=b)\n",
    "display(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop down selector for graph\n",
    "a=query_result.drop_duplicates(subset='componentType_code')\n",
    "query_list=[None] + list(a['componentType_code'])\n",
    "input_dropdown = alt.binding_select(options=query_list,name=\"Component Type Code:   \")\n",
    "selection = alt.selection_single(\n",
    "    fields=[\"componentType_code\"], bind=input_dropdown,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make plot\n",
    "alt.data_transformers.disable_max_rows()\n",
    "chart=alt.Chart(query_result).mark_line(point=True).encode(\n",
    "    x=alt.X('_time',title='Timeline'),\n",
    "    y=alt.Y('_value',title='Population'),\n",
    "    color=alt.Color('componentType_code', legend=alt.Legend(title='Component Code')),\n",
    "    tooltip=['_time','_value','componentType_code']\n",
    ").properties(\n",
    "    title={\n",
    "      \"text\": \"Component migration at Glasgow\", \n",
    "      \"subtitle\": \"Strips\"\n",
    "    },\n",
    "    width=600,\n",
    "    height=350\n",
    ").interactive().add_selection(selection).transform_filter(selection)\n",
    "\n",
    "\n",
    "chart.resolve_scale('independent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything has worked the graph about should be populated by points! You can run this script again and the points will turn into lines! If you keep running this script repeatedly for a while you'll start to changes in the population of components in the various stages. We can now move on to creating a datapane report to share our plot.\n",
    "\n",
    "For this next step we will have to create a datapane account [here is the link](https://datapane.com/getting-started/#), i would recomend loging with your GitHub account. Once you have done so please copy and paste your API token into the funciton below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.login(token='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.Report(\n",
    "    dp.Plot(chart),\n",
    "    dp.DataTable(query_result)\n",
    ").upload(name=\"Component migration at \"+str(myInstCode)+\": Strips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "God's speed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
